# -*- coding: utf-8 -*-
"""
ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ë“ˆ
"""
import os
import sys
import time
import logging
import hashlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import asyncio
from datetime import datetime, timedelta
from typing import Any, Optional, List, Tuple
from functools import wraps
from collections import deque

logger = logging.getLogger(__name__)

# ========== ë°ì´í„° íƒ€ì… ë³€í™˜ ==========
def convert_numpy_types(obj: Any) -> Any:
    """Numpy íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íŒŒì´ì¬ ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: convert_numpy_types(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(i) for i in obj]
    return obj

# ========== ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥ ==========
def plot_backtest_results(history_df, filename):
    """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì¢…í•© ì„±ëŠ¥ ì°¨íŠ¸ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    if history_df is None or history_df.empty:
        logger.warning("ì„±ê³¼ ê¸°ë¡ ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- 1. ë°ì´í„° ì¤€ë¹„ ---
    # ì½”ì¸ ëª©ë¡ì„ ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ì—ì„œ ë™ì ìœ¼ë¡œ ì¶”ì¶œ
    qty_cols = [col for col in history_df.columns if col.endswith('_qty')]
    coins = [col.replace('_qty', '') for col in qty_cols]

    # ê°€ê²© ì •ê·œí™” (ì‹œì‘ì ì„ 100ìœ¼ë¡œ)
    price_cols = [f'{c}_price' for c in coins if f'{c}_price' in history_df.columns and not history_df[f'{c}_price'].isnull().all()]
    if price_cols:
        df_for_norm = history_df[price_cols].copy()
        first_valid_prices = df_for_norm.bfill().iloc[0]
        first_valid_prices[first_valid_prices == 0] = np.nan # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        normalized_prices = (df_for_norm / first_valid_prices * 100)

        # ì •ê·œí™”ëœ ê°€ê²© ì»¬ëŸ¼ëª…ì„ ë§Œë“¤ ë•Œ, ì›ë˜ ì½”ì¸ ì´ë¦„ë§Œ ì‚¬ìš©
        norm_price_col_names = {orig_col: f'{coin}_norm_price' for orig_col, coin in zip(price_cols, coins)}
        normalized_prices.rename(columns=norm_price_col_names, inplace=True)
        history_df = pd.concat([history_df, normalized_prices], axis=1)

    # MDD ê³„ì‚°
    history_df['peak'] = history_df['portfolio_value'].cummax()
    history_df['drawdown'] = (history_df['portfolio_value'] - history_df['peak']) / history_df['peak'].replace(0, np.nan)

    # --- 2. ì°¨íŠ¸ ê·¸ë¦¬ê¸° ---
    fig, (ax1, ax2, ax3, ax4) = plt.subplots(
        4, 1, figsize=(15, 20), sharex=True, gridspec_kw={'height_ratios': [3, 2, 2, 1]}
    )
    fig.suptitle('Comprehensive Backtest Performance Analysis', fontsize=16)

    # [ì°¨íŠ¸ 1 í¬íŠ¸í´ë¦¬ì˜¤ ìì‚° êµ¬ì„±
    value_cols = [f'{c}_value' for c in coins if f'{c}_value' in history_df.columns]
    if value_cols or 'cash' in history_df.columns:
        history_df[value_cols + ['cash']].plot.area(ax=ax1, stacked=True, alpha=0.7)
    history_df['portfolio_value'].plot(ax=ax1, color='black', lw=2, label='Total Value', ls='--')
    ax1.set_ylabel('Portfolio Value ($)')
    ax1.set_title('Portfolio Asset Composition')
    ax1.legend()
    ax1.grid(True)

    # [ì°¨íŠ¸ 2 ìì‚° ê°€ê²© ì¶”ì´ (ì •ê·œí™”)
    norm_price_cols = [f'{c}_norm_price' for c in coins if f'{c}_norm_price' in history_df.columns]
    if norm_price_cols:
        history_df[norm_price_cols].plot(ax=ax2, alpha=0.8, lw=1.5)
        ax2.legend([col.replace('_norm_price', '') for col in norm_price_cols])
    ax2.set_ylabel('Normalized Price (Start=100)')
    ax2.set_title('Asset Price Trend')
    ax2.grid(True)

    # [ì°¨íŠ¸ 3 ì½”ì¸ë³„ ë³´ìœ  ìˆ˜ëŸ‰
    quantity_cols = [f'{c}_qty' for c in coins if f'{c}_qty' in history_df.columns]
    if quantity_cols:
        history_df[quantity_cols].plot(ax=ax3)
        ax3.set_ylabel('Quantity Held')
        ax3.set_title('Position Change by Coin')
        ax3.legend([col.replace('_qty', '') for col in quantity_cols])
    ax3.grid(True)

    # [ì°¨íŠ¸ 4] ìµœëŒ€ ë‚™í­ (MDD)
    ax4.fill_between(history_df.index, history_df['drawdown'] * 100, 0, color='red', alpha=0.4)
    ax4.set_ylabel('Drawdown (%)')
    ax4.set_title('Portfolio Drawdown (MDD)')
    ax4.grid(True)

    plt.xlabel('Date')
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    try:
        plt.savefig(filename, dpi=300)
        logger.info(f"ğŸ¨ ì„±ê³¼ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {filename}")
    except Exception as e:
        logger.error(f"ê·¸ë˜í”„ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        plt.close(fig)

def report_final_backtest_results(start_date, end_date, initial_balance, result: dict, prefix: str = ""):
    """ë°±í…ŒìŠ¤íŠ¸ ìµœì¢… ê²°ê³¼ë¥¼ ë¦¬í¬íŒ…í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë²”ìš© í•¨ìˆ˜"""
    if not result or 'portfolio_history' not in result or result['portfolio_history'].empty:
        logger.error("ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    summary = result['summary']
    portfolio_history_df = result['portfolio_history']
    trade_history_df = result.get('trade_history', pd.DataFrame())

    logger.info(f"\n{'='*80}\n ** {prefix} ìµœì¢… ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ **\n{'='*80}")
    logger.info(f"ì „ì²´ ê¸°ê°„: {start_date.date()} ~ {end_date.date()}")
    logger.info(f"ì´ˆê¸° ìë³¸: ${initial_balance:,.2f} | ìµœì¢… ìì‚°: ${summary['final_value']:,.2f}")
    logger.info(f"ì´ ìˆ˜ìµë¥ : {summary['total_return']:.2f}% | ìµœëŒ€ ë‚™í­ (MDD): {summary['mdd']:.2f}%")
    logger.info("="*80)

    # --- íŒŒì¼ ì €ì¥ ë¡œì§ ---
    now_str = datetime.now().strftime("%y%m%d_%H%M%S")
    prefix_str = f"{prefix}_" if prefix else ""
    
    output_dir = 'output'
    os.makedirs(output_dir, exist_ok=True)

    portfolio_filename = os.path.join(output_dir, f'{prefix_str}portfolio_history_{now_str}.csv')
    trade_filename = os.path.join(output_dir, f'{prefix_str}trade_history_{now_str}.csv')
    plot_filename = os.path.join(output_dir, f'{prefix_str}performance_{now_str}.png')

    portfolio_history_df.to_csv(portfolio_filename)
    logger.info(f"ğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„¸ ë‚´ì—­ ì €ì¥ ì™„ë£Œ: {portfolio_filename}")
    if not trade_history_df.empty:
        trade_history_df.to_csv(trade_filename, index=False)
        logger.info(f"TRADE_LOG ê±°ë˜ ìƒì„¸ ë‚´ì—­ ì €ì¥ ì™„ë£Œ: {trade_filename}")

    plot_backtest_results(portfolio_history_df, plot_filename)

# ========== í™˜ê²½ ê°ì§€ ==========
def detect_multiprocessing_mode() -> bool:
    """ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš© ì—¬ë¶€ ìë™ ê°ì§€"""
    script_name = os.path.basename(sys.argv[0])
    return (
        script_name.startswith('backtest') or 
        os.getenv("IS_BACKTEST_MODE", "false").lower() == 'true'
    )

# ========== íŒŒì¼/ë””ë ‰í† ë¦¬ ==========
def ensure_dir_exists(directory: str) -> None:
    """ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
    if directory and not os.path.exists(directory):
        os.makedirs(directory)
        
def get_log_filename(prefix: str, extension: str = 'log') -> str:
    """ë¡œê·¸ íŒŒì¼ëª… ìƒì„± (ë‚ ì§œ í¬í•¨)"""
    from datetime import datetime
    timestamp = datetime.now().strftime("%y%m%d_%H%M%S")
    return f"{prefix}_{timestamp}.{extension}"


# ========== ì‹œê°„/ë‚ ì§œ ==========
def parse_date_safe(date_str: str, default_format: str = '%Y-%m-%d') -> Optional[datetime]:
    """ì•ˆì „í•œ ë‚ ì§œ íŒŒì‹± (ì˜¤ë¥˜ ì‹œ None ë°˜í™˜)"""
    try:
        return datetime.strptime(date_str, default_format)
    except (ValueError, TypeError):
        return None

def get_date_range(start_date: str, end_date: str, default_format: str = '%Y-%m-%d') -> int:
    """ë‘ ë‚ ì§œ ì‚¬ì´ì˜ ì¼ìˆ˜ ê³„ì‚°"""
    start = parse_date_safe(start_date, default_format)
    end = parse_date_safe(end_date, default_format)
    if start and end:
        return (end - start).days
    return 0

def is_trading_hours(current_time: datetime = None, 
                     allowed_hours: list = None) -> bool:
    """ê±°ë˜ ê°€ëŠ¥ ì‹œê°„ì¸ì§€ í™•ì¸"""
    if current_time is None:
        current_time = datetime.now()
    
    if allowed_hours is None:
        return True  # ì œí•œ ì—†ìŒ
    
    current_hour = current_time.hour
    for start_hour, end_hour in allowed_hours:
        if start_hour <= current_hour < end_hour:
            return True
    return False


# ========== ë°ì½”ë ˆì´í„° ==========
def timing_decorator(func):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        elapsed_ms = (time.time() - start) * 1000
        logger.debug(f"{func.__name__} ì‹¤í–‰ ì‹œê°„: {elapsed_ms:.2f}ms")
        return result
    return wrapper

def log_exceptions(func):
    """ì˜ˆì™¸ ìë™ ë¡œê¹… ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"{func.__name__} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    return wrapper

# ========== ë°ì´í„° ê²€ì¦ ==========
def validate_price_data(price: float, symbol: str = "") -> bool:
    """ê°€ê²© ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
    if price is None or price <= 0:
        logger.warning(f"{symbol} ì˜ëª»ëœ ê°€ê²©: {price}")
        return False
    return True

def is_valid_ohlcv_row(row: dict) -> bool:
    """OHLCV ë°ì´í„° í•œ í–‰ì˜ ë…¼ë¦¬ì  ìœ íš¨ì„± ê²€ì¦"""
    try:
        o, h, l, c = row['open'], row['high'], row['low'], row['close']
        # Highê°€ ìµœê³ ê°€, Lowê°€ ìµœì €ê°€ì¸ì§€
        if h < max(o, l, c) or l > min(o, h, c):
            return False
        # ëª¨ë‘ ì–‘ìˆ˜ì¸ì§€
        if any(val <= 0 for val in [o, h, l, c]):
            return False
        return True
    except (KeyError, TypeError):
        return False

# ========== ìˆ˜í•™/í†µê³„ ==========
def normalize_value(value: float, min_val: float, max_val: float) -> float:
    """ê°’ì„ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”"""
    if max_val == min_val:
        return 0.5
    return (value - min_val) / (max_val - min_val)

def calculate_percentage_change(old_value: float, new_value: float) -> float:
    """ë°±ë¶„ìœ¨ ë³€í™” ê³„ì‚°"""
    if old_value == 0:
        return 0.0
    return ((new_value - old_value) / old_value) * 100

def safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:
    """0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€"""
    if denominator == 0:
        return default
    return numerator / denominator
    # ... (ìœ„ ì½”ë“œ)

# ========== ë¬¸ìì—´/í•´ì‹œ ==========
def generate_hash(text: str, algorithm: str = 'md5') -> str:
    """í…ìŠ¤íŠ¸ì˜ í•´ì‹œê°’ ìƒì„± (ì¤‘ë³µ ê°ì§€ìš©)"""
    hash_func = getattr(hashlib, algorithm)
    return hash_func(text.encode()).hexdigest()

def truncate_string(text: str, max_length: int = 50, suffix: str = '...') -> str:
    """ê¸´ ë¬¸ìì—´ ìë¥´ê¸°"""
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

# ========== Rate Limiter ==========
class RateLimiter:
    """API Rate Limiting ê´€ë¦¬ í´ë˜ìŠ¤"""
    def __init__(self, max_requests: int = 10, time_window: int = 60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = deque()
        self._lock = asyncio.Lock()
    
    async def acquire(self):
        """ìš”ì²­ ê¶Œí•œ íšë“ (í•„ìš”ì‹œ ëŒ€ê¸°)"""
        async with self._lock:
            now = time.time()
            
            # ì˜¤ë˜ëœ ìš”ì²­ ì œê±°
            while self.requests and self.requests[0] < now - self.time_window:
                self.requests.popleft()
            
            # í•œë„ ì´ˆê³¼ ì‹œ ëŒ€ê¸°
            if len(self.requests) >= self.max_requests:
                sleep_time = self.requests[0] + self.time_window - now + 0.1
                await asyncio.sleep(sleep_time)
                return await self.acquire()
            
            self.requests.append(now)
    
    def reset(self):
        """Rate limiter ì´ˆê¸°í™”"""
        self.requests.clear()


